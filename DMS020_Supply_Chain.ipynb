{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "<center><h1>Supply Chain Analysis</h1></center>\n",
    "\n",
    "___\n",
    "\n",
    "<center><h2>DSM020 - Data Programming in Python</h2></center><br>\n",
    "<center><strong>Teacher:</strong> Sean McGrath </center>\n",
    "\n",
    "___\n",
    "<p></p>\n",
    "<center style=\"color: #AA6373; font-weight: 400;\"><strong>Presented by:</strong></center>\n",
    "<center style=\"color: #AA6373; font-weight: 400;\">Jorge Forero L.</center>\n",
    "<center style=\"color: #AA6373; font-weight: 400;\">Student Number: 240323983</center>\n",
    "<center style=\"color: #AA6373; font-weight: 400;\">Student Portal Username: JEFL1</center>\n",
    "<center>September 2024</center>\n",
    "<p></p>"
   ],
   "id": "a8c65e47be45355a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction & Problem Statement\n",
    "<p></p>\n",
    "This project aims to predict late delivery risks in global supply chains by analyzing historical data from various markets, shipping modes, and customer segments. Using advanced data processing and machine learning techniques, we seek to uncover the key drivers of delivery delays and propose strategies to optimize logistics performance.\n",
    "\n",
    "We address the following key questions:\n",
    "\n",
    "1. What are the primary factors influencing late deliveries across markets and shipping methods?\n",
    "2. How can predictive models improve delivery accuracy and reduce delays?\n",
    "3. What data-driven strategies can enhance overall supply chain efficiency?\n",
    "\n",
    "By leveraging detailed data on orders, customers, and shipments, this analysis develops adaptive models to predict delivery risks and offers actionable insights for improving supply chain reliability and operational effectiveness.\n",
    "<p></p>\n"
   ],
   "id": "57d5154e4f7760c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Project background and Context\n",
    "<p></p>\n",
    "This project aims to address the challenges of late deliveries in global supply chains by leveraging real-time analytics and machine learning models. The growing complexity of supply chain operations across markets and shipping modes necessitates advanced analytical techniques to enhance visibility and minimize delays.\n",
    "\n",
    "The analysis focuses on two key hypotheses: first, that real-time data analytics can significantly improve supply chain visibility and reduce delivery delays; and second, that certain factors within the supply chain—such as shipping mode, market region, and product categories—contribute to the likelihood of delays. Using machine learning models, particularly Random Forest, we explore these relationships to identify actionable insights for optimizing logistics and improving customer satisfaction.\n",
    "\n",
    "Through this approach, we aim to provide data-driven strategies that enhance supply chain efficiency and reduce operational risks by predicting and mitigating late deliveries.\n",
    "<p></p>\n",
    "\n",
    "### Aims and Objectives\n",
    "<p></p>\n",
    "The primary aim of this project is to enhance supply chain visibility and reduce late deliveries by applying real-time analytics and machine learning models. We seek to identify key factors contributing to delivery delays, such as shipping modes, market regions, and product characteristics, and provide actionable insights that can improve operational efficiency and customer satisfaction.\n",
    "<p></p>\n",
    "\n",
    "#### Objectives\n",
    "<p></p>\n",
    "\n",
    "1. Identify both obvious and hidden patterns in the data using innovative visualization and clustering techniques to reveal insights into delivery risks.\n",
    "2. Develop ensemble models that adapt to dynamic supply chain conditions, using real-time trends to improve prediction accuracy.\n",
    "3. Offer data-driven recommendations for optimizing shipping and operations based on predictive insights to reduce delivery risks in real-time.\n",
    "4. Design a feedback loop for model retraining using new data to enhance prediction accuracy and adapt to evolving supply chain dynamics.\n",
    "5. Leverage insights to drive improvements not just in delivery times, but across inventory, customer satisfaction, and operational efficiency.\n",
    "<p></p>\n",
    "\n",
    "#### Ethical Considerations\n",
    "<p></p>\n",
    "Several ethical considerations were taken into account during the analysis:\n",
    "\n",
    "1. Data Privacy: Although the dataset does not include personally identifiable information (PII), all customer-related data was handled responsibly to ensure privacy and confidentiality. Measures were taken to anonymize any sensitive data.\n",
    "2. Transparency and Reproducibility: All steps of the analysis, from data preprocessing to model development, were documented clearly to ensure transparency and reproducibility. This enables other analysts to replicate the analysis and verify the results.\n",
    "3. Bias in Predictions: Predictive models can sometimes introduce or reinforce bias, particularly if the data contains underlying biases (e.g., regional disparities). We made efforts to ensure the fairness of the models by carefully analyzing feature importance and ensuring balanced evaluation metrics."
   ],
   "id": "190ddf0211abae8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:18:38.129577Z",
     "start_time": "2024-09-15T16:18:37.926007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Testing and Evaluation\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import unittest"
   ],
   "id": "52f31e09253afb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "In this phase, we collect, describe, and explore the dataset to gain insights into its structure and key attributes. For this project, we used publicly available data sourced from open data platforms [1]. The dataset was chosen based on the specific requirements outlined by the course instructor, ensuring relevance to the project’s objectives and the analysis of late delivery risks.\n",
    "For this project, we utilized a comprehensive supply chain dataset that includes order information, customer details, and shipping data. The dataset supports the quantitative testing of our hypotheses related to late deliveries and supply chain efficiency, with a focus on enhancing real-time visibility and identifying key factors that influence delivery performance."
   ],
   "id": "46ae8c5ddbaaf7af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rationale for Data Selection\n",
    "We selected this dataset to provide a robust foundation for analyzing late delivery risks across various markets and shipping modes. The dataset captures essential variables, enabling us to:\n",
    "\n",
    "1. Identify Critical Factors: By including shipping details, customer segments, geographical markets, and product categories, we can uncover factors that contribute to delivery delays and operational inefficiencies.\n",
    "2. Improve Predictive Accuracy: Using a rich dataset with a broad range of variables allows us to build predictive models that accurately forecast delivery risks, providing actionable insights for real-time operations.\n",
    "3. Enable Comprehensive Analysis: The dataset supports the analysis of patterns across different markets and shipping modes, enabling us to propose targeted strategies for reducing late deliveries.\n",
    "4. Support Hypothesis Testing: The data allows us to evaluate our two core hypotheses regarding supply chain visibility and the impact of product categories, order sizes, and discounts on delivery performance.\n",
    "\n",
    "### Data Utilized\n",
    "The dataset utilized for this project contains several key variables:\n",
    "\n",
    "- Shipping Information: Includes shipping modes, shipment dates, and delivery statuses, providing insight into the logistics of the supply chain.\n",
    "- Order Details: Contains information such as order sizes, order dates, and product categories, which are essential for identifying the likelihood of late deliveries.\n",
    "- Customer Data: Includes geographical regions, market segments, and customer types, helping us understand the impact of different customer profiles on delivery performance.\n",
    "- Delivery Outcomes: Variables related to delivery times, late deliveries, and delivery risks, which are crucial for building predictive models and evaluating performance.\n",
    "\n",
    "These variables allow us to explore the relationships between shipping modes, market regions, and product categories, helping us identify key drivers of delivery delays.\n",
    "\n",
    "### Limitations and constrains of the Data\n",
    "\n",
    "While the dataset provides comprehensive information for the analysis, there are several limitations and constraints to consider:\n",
    "\n",
    "1. Incomplete Data: Some records may have missing values, particularly in fields related to delivery times or customer details. This could impact the accuracy of the models and the analysis, although preprocessing steps were taken to handle missing data.\n",
    "2. Categorical Data Complexity: Variables such as shipping modes and market regions are categorical in nature, requiring encoding into numerical values for machine learning models. This transformation may introduce some bias or oversimplification in the analysis.\n",
    "3. Timeframe of Data: The data may not fully capture recent shifts in supply chain strategies or external factors (e.g., economic changes or pandemic-related disruptions) that could influence delivery performance."
   ],
   "id": "35de0e2ab358f858"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Features explanation \n",
    "\n",
    "|Feature| Explanation|\n",
    "|:-:|:---|\n",
    "|Type| Type of transaction made\n",
    "|Days for shipping (real)| Actual shipping days of the purchased product\n",
    "|Days for shipment (scheduled)| Days of scheduled delivery of the purchased product\n",
    "|Benefit per order| Earnings per order placed\n",
    "|Sales per customer| Total sales per customer made per customer\n",
    "|Delivery Status| Delivery status of orders| Advance shipping , Late delivery , Shipping canceled , Shipping on tim...\n",
    "|Late_delivery_risk| Categorical variable that indicates if sending is late (1), it is not late (0).\n",
    "|Category Id| Product category code\n",
    "|Category Name| Description of the product category\n",
    "|Customer City| City where the customer made the purchase\n",
    "|Customer Country| Country where the customer made the purchase\n",
    "|Customer Email| Customer's email\n",
    "|Customer Fname| Customer name\n",
    "|Customer Id| Customer ID\n",
    "|Customer Lname| Customer lastname\n",
    "|Customer Password| Masked customer key\n",
    "|Customer Segment| Types of Customers| Consumer , Corporate , Home Office\n",
    "|Customer State| State to which the store where the purchase is registered belongs\n",
    "|Customer Street| Street to which the store where the purchase is registered belongs\n",
    "|Customer Zipcode| Customer Zipcode\n",
    "|Department Id| Department code of store\n",
    "|Department Name| Department name of store\n",
    "|Latitude| Latitude corresponding to location of store\n",
    "|Longitude| Longitude corresponding to location of store\n",
    "|Market| Market to where the order is delivered | Africa , Europe , LATAM , Pacific Asia , USCA\n",
    "|Order City| Destination city of the order\n",
    "|Order Country| Destination country of the order\n",
    "|Order Customer Id| Customer order code\n",
    "|order date (DateOrders)| Date on which the order is made\n",
    "|Order Id| Order code\n",
    "|Order Item Cardprod Id| Product code generated through the RFID reader\n",
    "|Order Item Discount| Order item discount value\n",
    "|Order Item Discount Rate| Order item discount percentage\n",
    "|Order Item Id| Order item code\n",
    "|Order Item Product Price| Price of products without discount\n",
    "|Order Item Profit Ratio| Order Item Profit Ratio\n",
    "|Order Item Quantity| Number of products per order\n",
    "|Sales| Value in sales\n",
    "|Order Item Total| Total amount per order\n",
    "|Order Profit Per Order| Order Profit Per Order\n",
    "|Order Region| Region of the world where the order is delivered | Southeast Asia ,South Asia ,Oceania ,Eastern ...\n",
    "|Order State| State of the region where the order is delivered\n",
    "|Order Status| Order Status | COMPLETE , PENDING , CLOSED , PENDING_PAYMENT ,CANCELED , PROCESSING ,SUSPECTED_FR...\n",
    "|Product Card Id| Product code\n",
    "|Product Category Id| Product category code\n",
    "|Product Description| Product Description\n",
    "|Product Image| Link of visit and purchase of the product\n",
    "|Product Name| Product Name\n",
    "|Product Price| Product Price\n",
    "|Product Status| Status of the product stock |If it is 1 not available , 0 the product is available\n",
    "|Shipping date (DateOrders)| Exact date and time of shipment\n",
    "|Shipping Mode| The following shipping modes are presented | Standard Class , First Class , Second Class , Same D...\""
   ],
   "id": "dd86d05d1efe66c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Load",
   "id": "dce57e6114bc5f17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:18:46.896493Z",
     "start_time": "2024-09-15T16:18:43.801349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using the address for the .csv file from the GitHub repository\n",
    "url = 'https://raw.githubusercontent.com/jforeroluque/Supply_Chain_Analysis/main/DataCoSupplyChainDataset.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame, specifying the encoding - this is because of an issue in the loading of the dataset\n",
    "df_supply = pd.read_csv(url, encoding='ISO-8859-1', on_bad_lines='skip')\n",
    "\n",
    "# Display the DataFrame\n",
    "df_supply.head()"
   ],
   "id": "c8daf0087da4952",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Type  Days for shipping (real)  Days for shipment (scheduled)  \\\n",
       "0     DEBIT                         3                              4   \n",
       "1  TRANSFER                         5                              4   \n",
       "2      CASH                         4                              4   \n",
       "3     DEBIT                         3                              4   \n",
       "4   PAYMENT                         2                              4   \n",
       "\n",
       "   Benefit per order  Sales per customer   Delivery Status  \\\n",
       "0          91.250000          314.640015  Advance shipping   \n",
       "1        -249.089996          311.359985     Late delivery   \n",
       "2        -247.779999          309.720001  Shipping on time   \n",
       "3          22.860001          304.809998  Advance shipping   \n",
       "4         134.210007          298.250000  Advance shipping   \n",
       "\n",
       "   Late_delivery_risk  Category Id   Category Name Customer City  ...  \\\n",
       "0                   0           73  Sporting Goods        Caguas  ...   \n",
       "1                   1           73  Sporting Goods        Caguas  ...   \n",
       "2                   0           73  Sporting Goods      San Jose  ...   \n",
       "3                   0           73  Sporting Goods   Los Angeles  ...   \n",
       "4                   0           73  Sporting Goods        Caguas  ...   \n",
       "\n",
       "  Order Zipcode Product Card Id Product Category Id  Product Description  \\\n",
       "0           NaN            1360                  73                  NaN   \n",
       "1           NaN            1360                  73                  NaN   \n",
       "2           NaN            1360                  73                  NaN   \n",
       "3           NaN            1360                  73                  NaN   \n",
       "4           NaN            1360                  73                  NaN   \n",
       "\n",
       "                                  Product Image  Product Name Product Price  \\\n",
       "0  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "1  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "2  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "3  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "4  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "\n",
       "  Product Status shipping date (DateOrders)   Shipping Mode  \n",
       "0              0             2/3/2018 22:56  Standard Class  \n",
       "1              0            1/18/2018 12:27  Standard Class  \n",
       "2              0            1/17/2018 12:06  Standard Class  \n",
       "3              0            1/16/2018 11:45  Standard Class  \n",
       "4              0            1/15/2018 11:24  Standard Class  \n",
       "\n",
       "[5 rows x 53 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Days for shipping (real)</th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Benefit per order</th>\n",
       "      <th>Sales per customer</th>\n",
       "      <th>Delivery Status</th>\n",
       "      <th>Late_delivery_risk</th>\n",
       "      <th>Category Id</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>...</th>\n",
       "      <th>Order Zipcode</th>\n",
       "      <th>Product Card Id</th>\n",
       "      <th>Product Category Id</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Image</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Status</th>\n",
       "      <th>shipping date (DateOrders)</th>\n",
       "      <th>Shipping Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>314.640015</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2/3/2018 22:56</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-249.089996</td>\n",
       "      <td>311.359985</td>\n",
       "      <td>Late delivery</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/18/2018 12:27</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-247.779999</td>\n",
       "      <td>309.720001</td>\n",
       "      <td>Shipping on time</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/17/2018 12:06</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22.860001</td>\n",
       "      <td>304.809998</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/16/2018 11:45</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>298.250000</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/15/2018 11:24</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:18:50.519077Z",
     "start_time": "2024-09-15T16:18:50.516968Z"
    }
   },
   "cell_type": "code",
   "source": "print(df_supply.columns)",
   "id": "b815a5cd3f67b5f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Days for shipping (real)', 'Days for shipment (scheduled)',\n",
      "       'Benefit per order', 'Sales per customer', 'Delivery Status',\n",
      "       'Late_delivery_risk', 'Category Id', 'Category Name', 'Customer City',\n",
      "       'Customer Country', 'Customer Email', 'Customer Fname', 'Customer Id',\n",
      "       'Customer Lname', 'Customer Password', 'Customer Segment',\n",
      "       'Customer State', 'Customer Street', 'Customer Zipcode',\n",
      "       'Department Id', 'Department Name', 'Latitude', 'Longitude', 'Market',\n",
      "       'Order City', 'Order Country', 'Order Customer Id',\n",
      "       'order date (DateOrders)', 'Order Id', 'Order Item Cardprod Id',\n",
      "       'Order Item Discount', 'Order Item Discount Rate', 'Order Item Id',\n",
      "       'Order Item Product Price', 'Order Item Profit Ratio',\n",
      "       'Order Item Quantity', 'Sales', 'Order Item Total',\n",
      "       'Order Profit Per Order', 'Order Region', 'Order State', 'Order Status',\n",
      "       'Order Zipcode', 'Product Card Id', 'Product Category Id',\n",
      "       'Product Description', 'Product Image', 'Product Name', 'Product Price',\n",
      "       'Product Status', 'shipping date (DateOrders)', 'Shipping Mode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exploratory Data Analysis",
   "id": "1a8b51c87d6e1a0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Volume of the data",
   "id": "578919219aa63b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:18:56.086755Z",
     "start_time": "2024-09-15T16:18:56.084570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here we count the records and the features to understand the dataset size\n",
    "num_records = len(df_supply)\n",
    "num_features = len(df_supply.columns)\n",
    "\n",
    "print(f\"The dataset has {num_records} records and {num_features} features.\")"
   ],
   "id": "609f0a1ae97ae63f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 180519 records and 53 features.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Missing Values\n",
    "\n",
    "To ensure the integrity of the analysis, we will drop rows with missing values in key features that are critical to the predictive models and overall insights. By focusing on the most relevant variables, we minimize the impact of incomplete data while preserving the quality and accuracy of the analysis."
   ],
   "id": "a1c115fbfa21adc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:22:08.914754Z",
     "start_time": "2024-09-15T16:22:08.839907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dropping rows with missing values in critical columns\n",
    "df_cleaned = df_supply.dropna(subset=[\n",
    "    \"Late_delivery_risk\",\n",
    "    \"Order Item Product Price\",\n",
    "    \"Order Item Quantity\",\n",
    "    \"Days for shipment (scheduled)\",\n",
    "    \"Days for shipping (real)\",\n",
    "    \"Customer Segment\",\n",
    "    \"Order Country\",\n",
    "    \"Shipping Mode\"\n",
    "])\n",
    "\n",
    "# Show the first 5 rows of cleaned data\n",
    "df_cleaned.head(5)\n"
   ],
   "id": "8f3f67718984e020",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Type  Days for shipping (real)  Days for shipment (scheduled)  \\\n",
       "0     DEBIT                         3                              4   \n",
       "1  TRANSFER                         5                              4   \n",
       "2      CASH                         4                              4   \n",
       "3     DEBIT                         3                              4   \n",
       "4   PAYMENT                         2                              4   \n",
       "\n",
       "   Benefit per order  Sales per customer   Delivery Status  \\\n",
       "0          91.250000          314.640015  Advance shipping   \n",
       "1        -249.089996          311.359985     Late delivery   \n",
       "2        -247.779999          309.720001  Shipping on time   \n",
       "3          22.860001          304.809998  Advance shipping   \n",
       "4         134.210007          298.250000  Advance shipping   \n",
       "\n",
       "   Late_delivery_risk  Category Id   Category Name Customer City  ...  \\\n",
       "0                   0           73  Sporting Goods        Caguas  ...   \n",
       "1                   1           73  Sporting Goods        Caguas  ...   \n",
       "2                   0           73  Sporting Goods      San Jose  ...   \n",
       "3                   0           73  Sporting Goods   Los Angeles  ...   \n",
       "4                   0           73  Sporting Goods        Caguas  ...   \n",
       "\n",
       "  Order Zipcode Product Card Id Product Category Id  Product Description  \\\n",
       "0           NaN            1360                  73                  NaN   \n",
       "1           NaN            1360                  73                  NaN   \n",
       "2           NaN            1360                  73                  NaN   \n",
       "3           NaN            1360                  73                  NaN   \n",
       "4           NaN            1360                  73                  NaN   \n",
       "\n",
       "                                  Product Image  Product Name Product Price  \\\n",
       "0  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "1  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "2  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "3  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "4  http://images.acmesports.sports/Smart+watch   Smart watch         327.75   \n",
       "\n",
       "  Product Status shipping date (DateOrders)   Shipping Mode  \n",
       "0              0             2/3/2018 22:56  Standard Class  \n",
       "1              0            1/18/2018 12:27  Standard Class  \n",
       "2              0            1/17/2018 12:06  Standard Class  \n",
       "3              0            1/16/2018 11:45  Standard Class  \n",
       "4              0            1/15/2018 11:24  Standard Class  \n",
       "\n",
       "[5 rows x 53 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Days for shipping (real)</th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Benefit per order</th>\n",
       "      <th>Sales per customer</th>\n",
       "      <th>Delivery Status</th>\n",
       "      <th>Late_delivery_risk</th>\n",
       "      <th>Category Id</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>...</th>\n",
       "      <th>Order Zipcode</th>\n",
       "      <th>Product Card Id</th>\n",
       "      <th>Product Category Id</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Image</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Status</th>\n",
       "      <th>shipping date (DateOrders)</th>\n",
       "      <th>Shipping Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>314.640015</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2/3/2018 22:56</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-249.089996</td>\n",
       "      <td>311.359985</td>\n",
       "      <td>Late delivery</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/18/2018 12:27</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-247.779999</td>\n",
       "      <td>309.720001</td>\n",
       "      <td>Shipping on time</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/17/2018 12:06</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22.860001</td>\n",
       "      <td>304.809998</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/16/2018 11:45</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>298.250000</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.acmesports.sports/Smart+watch</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/15/2018 11:24</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Removing Unnecessary Columns\n",
    "\n",
    "We remove columns that do not contribute to the analysis or predictive models. By eliminating these irrelevant features, we streamline the dataset, reduce noise, and improve the efficiency of the data processing pipeline.\n"
   ],
   "id": "b036ddc55efa63cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:22:13.019956Z",
     "start_time": "2024-09-15T16:22:12.964916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['Customer Fname', 'Customer Id', 'Customer Lname', 'Customer Password','Customer Street', 'Customer Zipcode', 'Product Description', 'Product Image', 'Order Zipcode', 'Customer Email']\n",
    "\n",
    "# Drop the columns from the DataFrame\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "df_cleaned.head()"
   ],
   "id": "8a578105c97cf0bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Type  Days for shipping (real)  Days for shipment (scheduled)  \\\n",
       "0     DEBIT                         3                              4   \n",
       "1  TRANSFER                         5                              4   \n",
       "2      CASH                         4                              4   \n",
       "3     DEBIT                         3                              4   \n",
       "4   PAYMENT                         2                              4   \n",
       "\n",
       "   Benefit per order  Sales per customer   Delivery Status  \\\n",
       "0          91.250000          314.640015  Advance shipping   \n",
       "1        -249.089996          311.359985     Late delivery   \n",
       "2        -247.779999          309.720001  Shipping on time   \n",
       "3          22.860001          304.809998  Advance shipping   \n",
       "4         134.210007          298.250000  Advance shipping   \n",
       "\n",
       "   Late_delivery_risk  Category Id   Category Name Customer City  ...  \\\n",
       "0                   0           73  Sporting Goods        Caguas  ...   \n",
       "1                   1           73  Sporting Goods        Caguas  ...   \n",
       "2                   0           73  Sporting Goods      San Jose  ...   \n",
       "3                   0           73  Sporting Goods   Los Angeles  ...   \n",
       "4                   0           73  Sporting Goods        Caguas  ...   \n",
       "\n",
       "     Order Region      Order State     Order Status  Product Card Id  \\\n",
       "0  Southeast Asia  Java Occidental         COMPLETE             1360   \n",
       "1      South Asia         Rajastán          PENDING             1360   \n",
       "2      South Asia         Rajastán           CLOSED             1360   \n",
       "3         Oceania       Queensland         COMPLETE             1360   \n",
       "4         Oceania       Queensland  PENDING_PAYMENT             1360   \n",
       "\n",
       "  Product Category Id  Product Name  Product Price Product Status  \\\n",
       "0                  73  Smart watch          327.75              0   \n",
       "1                  73  Smart watch          327.75              0   \n",
       "2                  73  Smart watch          327.75              0   \n",
       "3                  73  Smart watch          327.75              0   \n",
       "4                  73  Smart watch          327.75              0   \n",
       "\n",
       "  shipping date (DateOrders)   Shipping Mode  \n",
       "0             2/3/2018 22:56  Standard Class  \n",
       "1            1/18/2018 12:27  Standard Class  \n",
       "2            1/17/2018 12:06  Standard Class  \n",
       "3            1/16/2018 11:45  Standard Class  \n",
       "4            1/15/2018 11:24  Standard Class  \n",
       "\n",
       "[5 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Days for shipping (real)</th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Benefit per order</th>\n",
       "      <th>Sales per customer</th>\n",
       "      <th>Delivery Status</th>\n",
       "      <th>Late_delivery_risk</th>\n",
       "      <th>Category Id</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>...</th>\n",
       "      <th>Order Region</th>\n",
       "      <th>Order State</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Product Card Id</th>\n",
       "      <th>Product Category Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>Product Status</th>\n",
       "      <th>shipping date (DateOrders)</th>\n",
       "      <th>Shipping Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>314.640015</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>Java Occidental</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>2/3/2018 22:56</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-249.089996</td>\n",
       "      <td>311.359985</td>\n",
       "      <td>Late delivery</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Rajastán</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/18/2018 12:27</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASH</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-247.779999</td>\n",
       "      <td>309.720001</td>\n",
       "      <td>Shipping on time</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>...</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Rajastán</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/17/2018 12:06</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBIT</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22.860001</td>\n",
       "      <td>304.809998</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/16/2018 11:45</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>298.250000</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1/15/2018 11:24</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Data Preprocessing Test\n",
    "\n",
    "This test ensures that the preprocessing steps work correctly."
   ],
   "id": "5f8d8c5353550e9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:24:39.537535Z",
     "start_time": "2024-09-15T16:24:39.523866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TestDataPreprocessing(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Sample DataFrame simulating df_supply\n",
    "        self.df_supply = pd.DataFrame({\n",
    "            'Late_delivery_risk': [1, np.nan, 0, 1, 0],\n",
    "            'Order Item Product Price': [100.0, 200.0, np.nan, 300.0, 150.0],\n",
    "            'Order Item Quantity': [2, 4, 5, np.nan, 6],\n",
    "            'Days for shipment (scheduled)': [5, 10, 15, 20, np.nan],\n",
    "            'Days for shipping (real)': [4, np.nan, 10, 12, 14],\n",
    "            'Customer Segment': ['Consumer', 'Corporate', np.nan, 'Home Office', 'Corporate'],\n",
    "            'Order Country': ['US', 'Germany', 'Brazil', 'France', np.nan],\n",
    "            'Shipping Mode': ['Standard Class', 'First Class', 'Second Class', np.nan, 'First Class'],\n",
    "            'Customer Fname': ['John', 'Jane', 'Alice', 'Bob', 'Charlie'],\n",
    "            'Customer Id': [1, 2, 3, 4, 5],\n",
    "            'Customer Lname': ['Doe', 'Smith', 'Johnson', 'Brown', 'Taylor'],\n",
    "            'Customer Password': ['pass1', 'pass2', 'pass3', 'pass4', 'pass5'],\n",
    "            'Customer Street': ['Street1', 'Street2', 'Street3', 'Street4', 'Street5'],\n",
    "            'Customer Zipcode': ['10001', '20002', '30003', '40004', '50005'],\n",
    "            'Product Description': ['Product1', 'Product2', 'Product3', 'Product4', 'Product5'],\n",
    "            'Product Image': ['img1', 'img2', 'img3', 'img4', 'img5'],\n",
    "            'Customer Email': ['email1', 'email2', 'email3', 'email4', 'email5'],\n",
    "            'Order Zipcode': ['10001', '20002', '30003', '40004', '50005'],\n",
    "        })\n",
    "\n",
    "    def test_dropna_critical_columns(self):\n",
    "        # Apply dropna for critical columns\n",
    "        critical_columns = [\n",
    "            \"Late_delivery_risk\",\n",
    "            \"Order Item Product Price\",\n",
    "            \"Order Item Quantity\",\n",
    "            \"Days for shipment (scheduled)\",\n",
    "            \"Days for shipping (real)\",\n",
    "            \"Customer Segment\",\n",
    "            \"Order Country\",\n",
    "            \"Shipping Mode\"\n",
    "        ]\n",
    "        df_cleaned = self.df_supply.dropna(subset=critical_columns)\n",
    "\n",
    "        # Check that no rows have missing values in critical columns\n",
    "        for col in critical_columns:\n",
    "            self.assertEqual(df_cleaned[col].isnull().sum(), 0, f\"Missing values found in {col}\")\n",
    "\n",
    "    def test_drop_unnecessary_columns(self):\n",
    "        # List of columns to drop\n",
    "        columns_to_drop = ['Customer Fname', 'Customer Id', 'Customer Lname', 'Customer Password','Customer Street', 'Customer Zipcode', 'Product Description', 'Product Image', 'Order Zipcode', 'Customer Email']\n",
    "\n",
    "        # Apply the drop operation\n",
    "        df_cleaned = self.df_supply.drop(columns=columns_to_drop)\n",
    "\n",
    "        # Test that the unnecessary columns are dropped\n",
    "        for col in columns_to_drop:\n",
    "            self.assertNotIn(col, df_cleaned.columns, f\"{col} was not dropped\")\n",
    "\n",
    "# Run the test in Jupyter\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ],
   "id": "f16325d4e5159768",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Numerical Feature Summary",
   "id": "4b2086a0dfddeff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary statistics\n",
    "print(df_cleaned.describe())"
   ],
   "id": "d8b4e4e67571c317",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Categorical Feature Summary\n",
    "\n",
    "Here we assess the distribution of values across categorical features and identifying missing data"
   ],
   "id": "82bd2e9beb8b9823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set the count to distinct values in each categorical feature\n",
    "for col_name in ['Shipping Mode', 'Order Region', 'Order Country', 'Product Category Id', 'Customer Segment', 'Order Status', 'Market']:\n",
    "    print(f\"\\nDistinct counts for {col_name}:\")\n",
    "    print(df_cleaned[col_name].value_counts())\n"
   ],
   "id": "cb51531b25bd4f46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count the number of missing values in each column to be sure\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df_cleaned.isnull().sum())"
   ],
   "id": "ecc2142b6535c817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Class Imbalance Analysis\n",
    "\n",
    "Here we determine the distribution of the target feature \"Late Delivery Risk\" where we want to assess class imbalance that is a critical factor to implement Machine Learning Models"
   ],
   "id": "887a7742b3553630"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count the number of occurrences for each class in 'Late_delivery_risk'\n",
    "late_delivery_counts = df_cleaned['Late_delivery_risk'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Count of occurrences for each class in 'Late_delivery_risk':\")\n",
    "print(late_delivery_counts)"
   ],
   "id": "a5f33cf92d6b7556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the total number of records\n",
    "total_count = len(df_cleaned)\n",
    "\n",
    "# Calculate the percentage distribution\n",
    "late_delivery_percentage = (late_delivery_counts / total_count) * 100\n",
    "\n",
    "# Combine counts and percentages into a DataFrame\n",
    "late_delivery_distribution = pd.DataFrame({\n",
    "    'count': late_delivery_counts,\n",
    "    'percentage': late_delivery_percentage\n",
    "})\n",
    "\n",
    "# Display the distribution\n",
    "print(\"\\nDistribution in terms of percentages:\")\n",
    "late_delivery_distribution"
   ],
   "id": "a6b6956a4ac5c684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Count occurrences of 'Late_delivery_risk' using pandas\n",
    "late_delivery_risk_df = df_cleaned.groupby(\"Late_delivery_risk\").size().reset_index(name='count')\n",
    "\n",
    "# Plot Late Delivery Risk using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Late_delivery_risk', y='count', hue='Late_delivery_risk', data=late_delivery_risk_df, palette='Blues_d', legend=False)\n",
    "plt.xlabel('Late Delivery Risk')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Late Delivery Risk')\n",
    "plt.show()"
   ],
   "id": "8c662c66e86448b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Correlation Analysis (Numerical Features)\n",
    "\n",
    "Here we try to understand and identify the strength and direction of relationships between the numerical features and the target variable \"Late Delivery Risk\"."
   ],
   "id": "970fe5fab31ed012"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of numerical columns to calculate the correlation with 'Late_delivery_risk'\n",
    "numerical_columns_corr = ['Days for shipment (scheduled)', 'Order Item Quantity', 'Order Item Total', 'Sales', 'Order Item Product Price']\n",
    "\n",
    "# Ensure 'Late_delivery_risk' is numeric for correlation (if needed)\n",
    "df_cleaned['Late_delivery_risk'] = pd.to_numeric(df_cleaned['Late_delivery_risk'], errors='coerce')\n",
    "\n",
    "# Calculate and print the correlation for each numerical column with 'Late_delivery_risk'\n",
    "for col_name in numerical_columns_corr:\n",
    "    correlation = df_cleaned[[col_name, 'Late_delivery_risk']].corr().iloc[0, 1]\n",
    "    print(f\"Correlation between {col_name} and Late_delivery_risk: {correlation}\")"
   ],
   "id": "50faf87b80028387",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Shipping mode Analysis\n",
    "\n",
    "This analysis would enable to evaluate the Shipping mode performance by looking at how frequently late daliveries occur for each shipping method. With this the company can determine which shipping methods may require optimization or further investigation to reduce late deliveries."
   ],
   "id": "9c532ad0fb0eecfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by 'Shipping Mode' and calculate the number of late deliveries and total deliveries\n",
    "shipping_mode_analysis = df_cleaned.groupby('Shipping Mode').agg(\n",
    "    Late_Delivery_Count=pd.NamedAgg(column='Late_delivery_risk', aggfunc=lambda x: (x == 1).sum()),\n",
    "    Total_Deliveries=pd.NamedAgg(column='Late_delivery_risk', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the percentage of late deliveries for each shipping mode\n",
    "shipping_mode_analysis['Late_Delivery_Percentage'] = (shipping_mode_analysis['Late_Delivery_Count'] / shipping_mode_analysis['Total_Deliveries']) * 100\n",
    "\n",
    "# Display the result\n",
    "shipping_mode_analysis"
   ],
   "id": "973159d0ad044dfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count occurrences of 'Shipping Mode' and 'Late_delivery_risk' using pandas\n",
    "shipping_mode_df = df_cleaned.groupby([\"Shipping Mode\", \"Late_delivery_risk\"]).size().reset_index(name='count')\n",
    "\n",
    "# Create a pivot table for visualization\n",
    "shipping_mode_pivot = shipping_mode_df.pivot(index='Shipping Mode', columns='Late_delivery_risk', values='count')\n",
    "\n",
    "# Plot Shipping Mode vs Late Delivery using seaborn\n",
    "shipping_mode_pivot.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='Blues')\n",
    "plt.title(\"Shipping Mode vs Late Delivery Risk\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ],
   "id": "f97820108706acfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(x=\"Shipping Mode\", y=\"Late_Delivery_Percentage\", hue='Shipping Mode', data=shipping_mode_analysis, palette='Blues_d')\n",
    "\n",
    "plt.xlabel('Shipping Mode')\n",
    "plt.ylabel('Late Delivery Percentage (%)')\n",
    "plt.title('Late Delivery Percentage by Shipping Mode')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "3ef3cb9c1ee519c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Geographical Analysis\n",
    "\n",
    "This analysis evaluates geographical impact on the late daliveries by breaking down the data by Market, Order City, and Order Country. With this the company can understand which regions are experiencing more late deliveries."
   ],
   "id": "5f8452bbcd85ec66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by 'Market', 'Order City', and 'Order Country' and calculate late deliveries and total deliveries\n",
    "geo_analysis = df_cleaned.groupby(['Market', 'Order City', 'Order Country']).agg(\n",
    "    Late_Delivery_Count=pd.NamedAgg(column='Late_delivery_risk', aggfunc=lambda x: (x == 1).sum()),\n",
    "    Total_Deliveries=pd.NamedAgg(column='Late_delivery_risk', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the percentage of late deliveries\n",
    "geo_analysis['Late_Delivery_Percentage'] = (geo_analysis['Late_Delivery_Count'] / geo_analysis['Total_Deliveries']) * 100\n",
    "\n",
    "# Sort by Late_Delivery_Count in descending order\n",
    "geo_analysis = geo_analysis.sort_values(by='Late_Delivery_Count', ascending=False)\n",
    "\n",
    "# Display the result without truncation\n",
    "pd.set_option('display.max_rows', None)  # Ensure all rows are shown\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are shown\n",
    "pd.set_option('display.width', None)  # Adjust display width\n",
    "\n",
    "# Show the result\n",
    "geo_analysis.head(10)"
   ],
   "id": "ce8a81ad1f2375b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Top 10 Cities by Late Delivery Count\n",
    "top_cities = geo_analysis.sort_values(by='Late_Delivery_Count', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Late_Delivery_Count', y='Order City', hue='Order City', data=top_cities, palette='Reds_d')\n",
    "plt.title('Top 10 Cities with Highest Late Delivery Risk Count')\n",
    "plt.xlabel('Late Delivery Count')\n",
    "plt.ylabel('City')\n",
    "plt.show()"
   ],
   "id": "e083841348f545eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Top 10 Countries by Late Delivery Count\n",
    "top_countries = geo_analysis.groupby('Order Country').agg(\n",
    "    Late_Delivery_Count=pd.NamedAgg(column='Late_Delivery_Count', aggfunc='sum'),\n",
    "    Total_Deliveries=pd.NamedAgg(column='Total_Deliveries', aggfunc='sum')\n",
    ").reset_index()\n",
    "\n",
    "top_countries = top_countries.sort_values(by='Late_Delivery_Count', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Late_Delivery_Count', y='Order Country', hue='Order Country', data=top_countries, palette='Blues_d')\n",
    "plt.title('Top 10 Countries with Highest Late Delivery Risk Count')\n",
    "plt.xlabel('Late Delivery Count')\n",
    "plt.ylabel('Country')\n",
    "plt.show()"
   ],
   "id": "258f2e5f90e41b10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Product Category Analysis\n",
    "\n",
    "Here we evaluate the imact of the product categories on late deliveries. With this we aim to identify which product categories are more prone to late deliveries, offering insights into potential logistical inefficiencies for certain products."
   ],
   "id": "12a5ae07b044c4f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by 'Category Name' and calculate late deliveries and total deliveries\n",
    "product_category_analysis = df_cleaned.groupby('Category Name').agg(\n",
    "    Late_Delivery_Count=pd.NamedAgg(column='Late_delivery_risk', aggfunc=lambda x: (x == 1).sum()),\n",
    "    Total_Deliveries=pd.NamedAgg(column='Late_delivery_risk', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the percentage of late deliveries for each product category\n",
    "product_category_analysis['Late_Delivery_Percentage'] = (product_category_analysis['Late_Delivery_Count'] / product_category_analysis['Total_Deliveries']) * 100\n",
    "\n",
    "# Sort by Late_Delivery_Count in descending order\n",
    "product_category_analysis = product_category_analysis.sort_values(by='Late_Delivery_Count', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "product_category_analysis"
   ],
   "id": "41e1bc5f8ffa177c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sort the data by Late_Delivery_Percentage in descending order\n",
    "product_category_analysis = product_category_analysis.sort_values(by=\"Late_Delivery_Percentage\", ascending=False)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot using seaborn with hue and palette\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Category Name\", y=\"Late_Delivery_Percentage\", data=product_category_analysis, palette=\"Blues_d\", hue=\"Category Name\")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Late Delivery Percentage (%)')\n",
    "plt.title('Late Delivery Percentage by Product Category')\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "43cb4e401da2db8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Hypothesis 1 - Supply Chain Optimization\n",
    "\n",
    "\"Improved supply chain visibility through real-time analytics reduces the frequency of late deliveries.\"\n",
    "\n",
    "Here we aim to levarage real-time analytics to improve supply chain visibility and reduce late deliveries. by analyzing various features related to shipping schediles, order details, and egographical factors we can build predective models to identify the key drivers of late deliveries."
   ],
   "id": "b1f10fddee92f2d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "We first used StringIndexer to convert the categorical columns Market and Shipping Mode into numerical indices for model processing. A new feature, Price per Item, was created by dividing the total product price by the quantity sold.\n",
    "\n",
    "Additionally, we generated two interaction terms: Days_Market_Interaction and Days_ShippingMode_Interaction. These capture the combined effects of scheduled shipping days with market regions and shipping modes, respectively, to better model regional and logistical variations in delivery performance."
   ],
   "id": "406a62a8bea6f9e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Index the 'Market' and 'Shipping Mode' columns\n",
    "label_encoder_market = LabelEncoder()\n",
    "label_encoder_shipping_mode = LabelEncoder()\n",
    "\n",
    "df_cleaned['Market_index'] = label_encoder_market.fit_transform(df_cleaned['Market'])\n",
    "df_cleaned['Shipping_Mode_index'] = label_encoder_shipping_mode.fit_transform(df_cleaned['Shipping Mode'])\n"
   ],
   "id": "58c596c0a30ed9e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature Engineering: Creating interaction terms and additional features\n",
    "df_cleaned['Price_per_item'] = df_cleaned['Order Item Product Price'] / df_cleaned['Order Item Quantity']\n",
    "df_cleaned['Days_Market_Interaction'] = df_cleaned['Days for shipment (scheduled)'] * df_cleaned['Market_index']\n",
    "df_cleaned['Days_ShippingMode_Interaction'] = df_cleaned['Days for shipment (scheduled)'] * df_cleaned['Shipping_Mode_index']\n"
   ],
   "id": "86cd6f9a96aa1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Handling Categorical Features\n",
    "\n",
    "Here we prepare the categorical and numerical features applying ColumnTransformer to convert them into numerical"
   ],
   "id": "3d047e02b7bc53aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a list of categorical and numerical columns\n",
    "categorical_features_h1 = ['Order Region', 'Order Country', 'Product Category Id', 'Customer Segment', 'Order Status']\n",
    "numeric_features_h1 = ['Days for shipment (scheduled)', 'Order Item Quantity', 'Order Item Total','Price_per_item', 'Days_Market_Interaction', 'Days_ShippingMode_Interaction', 'Order Item Discount Rate']\n"
   ],
   "id": "c1c2e45ff88c516b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We'll use ColumnTransformer to handle both OneHotEncoding and numerical scaling in one pipeline.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_h1),  # OneHotEncoder for categorical features\n",
    "        ('num', StandardScaler(), numeric_features_h1)      # StandardScaler for numerical features\n",
    "    ]\n",
    ")\n"
   ],
   "id": "511f7d2e3da811cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature Engineering Test",
   "id": "9cfd2554f694af95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TestFeatureEngineeringHypothesis1(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Example data setup (use a small sample of data or your actual df_cleaned DataFrame)\n",
    "        self.df_cleaned = pd.DataFrame({\n",
    "            'Market': ['APAC', 'EMEA', 'LATAM'],\n",
    "            'Shipping Mode': ['Standard Class', 'Second Class', 'First Class'],\n",
    "            'Order Item Product Price': [100, 200, 300],\n",
    "            'Order Item Quantity': [2, 4, 6],\n",
    "            'Days for shipment (scheduled)': [5, 10, 15]\n",
    "        })\n",
    "\n",
    "        # Feature Engineering from your Hypothesis 1\n",
    "        self.label_encoder_market = LabelEncoder()\n",
    "        self.label_encoder_shipping_mode = LabelEncoder()\n",
    "\n",
    "        self.df_cleaned['Market_index'] = self.label_encoder_market.fit_transform(self.df_cleaned['Market'])\n",
    "        self.df_cleaned['Shipping_Mode_index'] = self.label_encoder_shipping_mode.fit_transform(self.df_cleaned['Shipping Mode'])\n",
    "\n",
    "        self.df_cleaned['Price_per_item'] = self.df_cleaned['Order Item Product Price'] / self.df_cleaned['Order Item Quantity']\n",
    "        self.df_cleaned['Days_Market_Interaction'] = self.df_cleaned['Days for shipment (scheduled)'] * self.df_cleaned['Market_index']\n",
    "        self.df_cleaned['Days_ShippingMode_Interaction'] = self.df_cleaned['Days for shipment (scheduled)'] * self.df_cleaned['Shipping_Mode_index']\n",
    "\n",
    "    def test_market_index(self):\n",
    "        # Check if Market_index is correctly encoded\n",
    "        market_mapping = {label: idx for idx, label in enumerate(self.label_encoder_market.classes_)}\n",
    "        self.assertEqual(self.df_cleaned['Market_index'].iloc[0], market_mapping['APAC'])\n",
    "        self.assertEqual(self.df_cleaned['Market_index'].iloc[1], market_mapping['EMEA'])\n",
    "        self.assertEqual(self.df_cleaned['Market_index'].iloc[2], market_mapping['LATAM'])\n",
    "\n",
    "    def test_shipping_mode_index(self):\n",
    "        # Check if Shipping_Mode_index is correctly encoded\n",
    "        shipping_mapping = {label: idx for idx, label in enumerate(self.label_encoder_shipping_mode.classes_)}\n",
    "        self.assertEqual(self.df_cleaned['Shipping_Mode_index'].iloc[0], shipping_mapping['Standard Class'])\n",
    "        self.assertEqual(self.df_cleaned['Shipping_Mode_index'].iloc[1], shipping_mapping['Second Class'])\n",
    "        self.assertEqual(self.df_cleaned['Shipping_Mode_index'].iloc[2], shipping_mapping['First Class'])\n",
    "\n",
    "    def test_price_per_item(self):\n",
    "        # Test if Price_per_item is calculated correctly\n",
    "        self.assertAlmostEqual(self.df_cleaned['Price_per_item'].iloc[0], 100 / 2)\n",
    "        self.assertAlmostEqual(self.df_cleaned['Price_per_item'].iloc[1], 200 / 4)\n",
    "        self.assertAlmostEqual(self.df_cleaned['Price_per_item'].iloc[2], 300 / 6)\n",
    "\n",
    "    def test_days_market_interaction(self):\n",
    "        # Test if Days_Market_Interaction is calculated correctly\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_Market_Interaction'].iloc[0], 5 * self.df_cleaned['Market_index'].iloc[0])\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_Market_Interaction'].iloc[1], 10 * self.df_cleaned['Market_index'].iloc[1])\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_Market_Interaction'].iloc[2], 15 * self.df_cleaned['Market_index'].iloc[2])\n",
    "\n",
    "    def test_days_shipping_mode_interaction(self):\n",
    "        # Test if Days_ShippingMode_Interaction is calculated correctly\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_ShippingMode_Interaction'].iloc[0], 5 * self.df_cleaned['Shipping_Mode_index'].iloc[0])\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_ShippingMode_Interaction'].iloc[1], 10 * self.df_cleaned['Shipping_Mode_index'].iloc[1])\n",
    "        self.assertAlmostEqual(self.df_cleaned['Days_ShippingMode_Interaction'].iloc[2], 15 * self.df_cleaned['Shipping_Mode_index'].iloc[2])\n",
    "\n",
    "# Run the test in Jupyter\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ],
   "id": "31f6af72ece3ca63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modeling and Evaluation",
   "id": "cb204be25cf2308"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Model Training\n",
    "\n",
    "In here we define the Random Forest classifier model, starting with building the pipeline to include the feature processing and the model, then we split the data into training and testing sets, fits the model on the training data, makes predictions and evaluates the model's performance using the Area Under the ROC Curve (AUC)"
   ],
   "id": "3d714ad818d9dc39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assemble the final features and define the RandomForest model\n",
    "rf_Supply = RandomForestClassifier(n_estimators=100, random_state=42)"
   ],
   "id": "4f7e85163e99efc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a pipeline\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf_Supply)\n",
    "])"
   ],
   "id": "5c5b38191acb7a6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_cleaned[categorical_features_h1 + numeric_features_h1 + ['Market_index', 'Shipping_Mode_index']]\n",
    "y = df_cleaned['Late_delivery_risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ],
   "id": "a3e7965a5628b54f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the model and make predictions\n",
    "rf_model = pipeline_rf.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
    "\n",
    "# Evaluate the model\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Random Forest AUC: {auc}\")"
   ],
   "id": "98a58ba7985e140e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Handle Class Imbalance\n",
    "\n",
    "In this code, we use cross-validation to optimize the Random Forest model by testing different maxDepth and numTrees values. After fitting the model, we evaluate its performance with the cross-validated AUC score, ensuring better model generalization."
   ],
   "id": "7e25e68e4f6d9217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [5, 10, 15],       # Grid for maximum depth\n",
    "    'classifier__n_estimators': [50, 100],      # Grid for number of trees\n",
    "    'classifier__min_samples_split': [2, 5],    # Grid for minimum samples to split a node\n",
    "}\n",
    "\n",
    "# Use AUC as the scoring metric\n",
    "scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# Set up GridSearchCV for cross-validation and hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid, scoring=scorer, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the cross-validated model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from cross-validation\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_cv = best_model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
    "\n",
    "# Evaluate the best model using AUC\n",
    "auc_rf_cv = roc_auc_score(y_test, y_pred_cv)\n",
    "print(f\"Random Forest Cross-Validated AUC: {auc_rf_cv}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ],
   "id": "ce393b3bb62a2448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming best_model is the trained pipeline\n",
    "rf_model = best_model.named_steps['classifier']\n",
    "\n",
    "# Get feature importances from RandomForestClassifier\n",
    "rf_feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Get the feature names after OneHotEncoding and scaling\n",
    "onehot_feature_names = best_model.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(categorical_features_h1)\n",
    "all_feature_names = np.hstack([onehot_feature_names, numeric_features_h1, ['Market_index', 'Shipping_Mode_index']])\n",
    "\n",
    "# If the number of feature importances is different from feature names (e.g., sparse features), trim it\n",
    "if len(all_feature_names) != len(rf_feature_importances):\n",
    "    all_feature_names = all_feature_names[:len(rf_feature_importances)]\n",
    "\n",
    "# Create a DataFrame with feature names and their importances\n",
    "importance_data = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': rf_feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 20 important features\n",
    "print(\"Top 20 Important Features:\")\n",
    "print(importance_data.head(20))"
   ],
   "id": "b4ab22702602634f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the top 20 important features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_data['Feature'].head(20), importance_data['Importance'].head(20), color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Important Features from Random Forest')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()\n",
    "\n",
    "# Function to map one-hot encoded features back to their original category names\n",
    "def get_original_category(feature_name):\n",
    "    if '_ohe_' in feature_name:\n",
    "        col_name, index = feature_name.split('_ohe_h1_')\n",
    "        index = int(index)\n",
    "\n",
    "        # Mapping OneHotEncoder categories back to their original labels\n",
    "        encoder = best_model.named_steps['preprocessor'].transformers_[0][1]\n",
    "        original_labels = encoder.categories_[categorical_features_h1.index(col_name)]\n",
    "\n",
    "        if index < len(original_labels):\n",
    "            return original_labels[index]\n",
    "        else:\n",
    "            return \"Unknown Category\"\n",
    "    return feature_name\n",
    "\n",
    "# Apply the function to map feature names back to their original categories\n",
    "importance_data['Original Category'] = importance_data['Feature'].apply(get_original_category)\n",
    "\n",
    "# Display the top 20 features with their original categories\n",
    "print(\"Top 20 Important Features with Original Categories:\")\n",
    "print(importance_data[['Feature', 'Original Category', 'Importance']].head(20))"
   ],
   "id": "86947b9bdd0833d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Hypothesis 2: Product and Operational Factors\n",
    "\n",
    "\"Certain product categories, order sizes, and discount rates significantly increase the risk of late deliveries, leading to potential customer dissatisfaction.\"\n",
    "\n",
    "This hypothesis would help us to identify specific operational factors that directly influence late deliveries so the company can focus on business practices that can change to improve delivery efficiency."
   ],
   "id": "5f94540401b4aca4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Dynamic Feature Encoding\n",
    "\n",
    "Here we apply StringIndexer and OneHotEncoder only when necessary, avoiding duplication. It then assembles the categorical and numerical features into a feature vector for the second model, stored in the features_h2 column."
   ],
   "id": "ac20bc829ec4cc46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define categorical features for Hypothesis 2\n",
    "categorical_features_h2 = ['Order Region', 'Order Country', 'Product Category Id', 'Customer Segment', 'Order Status', 'Shipping Mode']\n"
   ],
   "id": "7dec3d26c98d4b3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create lists to store indexers and encoders\n",
    "indexers_h2 = []\n",
    "encoders_h2 = []\n",
    "\n",
    "# Apply LabelEncoder (equivalent to StringIndexer in PySpark) and OneHotEncoder\n",
    "for column in categorical_features_h2:\n",
    "    indexed_col = column + \"_index_h2\"\n",
    "    ohe_col = column + \"_ohe_h2\"\n",
    "\n",
    "    if indexed_col not in df_cleaned.columns:\n",
    "        # Apply LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_cleaned[indexed_col] = label_encoder.fit_transform(df_cleaned[column])\n",
    "        indexers_h2.append(label_encoder)\n",
    "    else:\n",
    "        print(f\"Skipping LabelEncoder for {column} as {indexed_col} already exists\")"
   ],
   "id": "b7d4cbcef5701fd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define preprocessing for the pipeline\n",
    "preprocessor_h2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_h2),  # OneHotEncoder for categorical features\n",
    "        ('num', StandardScaler(), numeric_features_h1)      # StandardScaler for numerical features\n",
    "    ]\n",
    ")"
   ],
   "id": "17e273f9edcea70e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature Engineering Test",
   "id": "dfd4030c9aaa3f4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TestFeatureEngineeringHypothesis2(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Sample data for testing\n",
    "        self.df_cleaned = pd.DataFrame({\n",
    "            'Order Region': ['APAC', 'EMEA', 'LATAM'],\n",
    "            'Order Country': ['India', 'Germany', 'Brazil'],\n",
    "            'Product Category Id': [1, 2, 3],\n",
    "            'Customer Segment': ['Consumer', 'Corporate', 'Home Office'],\n",
    "            'Order Status': ['Pending', 'Complete', 'Canceled'],\n",
    "            'Shipping Mode': ['Standard Class', 'Second Class', 'First Class'],\n",
    "            'Order Item Total': [1000, 1500, 1200],\n",
    "            'Order Item Quantity': [10, 15, 12],\n",
    "            'Order Item Discount Rate': [0.1, 0.15, 0.12]\n",
    "        })\n",
    "\n",
    "        # Hypothesis 2 feature engineering process\n",
    "        self.categorical_features_h2 = ['Order Region', 'Order Country', 'Product Category Id', 'Customer Segment', 'Order Status', 'Shipping Mode']\n",
    "        self.numeric_features_h2 = ['Order Item Total', 'Order Item Quantity', 'Order Item Discount Rate']\n",
    "\n",
    "        # Apply LabelEncoder to categorical features\n",
    "        for column in self.categorical_features_h2:\n",
    "            indexed_col = column + \"_index_h2\"\n",
    "            label_encoder = LabelEncoder()\n",
    "            self.df_cleaned[indexed_col] = label_encoder.fit_transform(self.df_cleaned[column])\n",
    "\n",
    "        # Define the ColumnTransformer for preprocessing\n",
    "        self.preprocessor_h2 = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), self.categorical_features_h2),  # OneHotEncoder for categorical features\n",
    "                ('num', StandardScaler(), self.numeric_features_h2)      # StandardScaler for numerical features\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def test_label_encoder(self):\n",
    "        # Test if LabelEncoder works as expected\n",
    "        label_encoder = LabelEncoder()\n",
    "        expected_order_region_index = label_encoder.fit_transform(['APAC', 'EMEA', 'LATAM'])\n",
    "        self.assertTrue((self.df_cleaned['Order Region_index_h2'] == expected_order_region_index).all())\n",
    "\n",
    "    def test_one_hot_encoding(self):\n",
    "        # Fit the preprocessor to the data\n",
    "        transformed = self.preprocessor_h2.fit_transform(self.df_cleaned)\n",
    "\n",
    "        # Extract the OneHotEncoder part\n",
    "        ohe_transformer = self.preprocessor_h2.named_transformers_['cat']\n",
    "        ohe_features = ohe_transformer.get_feature_names_out(self.categorical_features_h2)\n",
    "\n",
    "        # Test that one-hot encoding generated the expected number of columns\n",
    "        self.assertEqual(len(ohe_features), len(ohe_transformer.categories_[0]) + len(ohe_transformer.categories_[1])\n",
    "                         + len(ohe_transformer.categories_[2]) + len(ohe_transformer.categories_[3])\n",
    "                         + len(ohe_transformer.categories_[4]) + len(ohe_transformer.categories_[5]))\n",
    "\n",
    "    def test_standard_scaler(self):\n",
    "        # Test if StandardScaler was applied to numeric columns\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(self.df_cleaned[self.numeric_features_h2])\n",
    "\n",
    "        # Fit the preprocessor to get scaled numeric data\n",
    "        preprocessed_data = self.preprocessor_h2.fit_transform(self.df_cleaned)\n",
    "\n",
    "        # The numeric features will appear after the one-hot encoded features\n",
    "        numeric_start_idx = self.preprocessor_h2.transformers[0][1].get_feature_names_out(self.categorical_features_h2).shape[0]\n",
    "\n",
    "        # Extract the scaled numeric data from the preprocessed output\n",
    "        scaled_numeric_data_from_pipeline = preprocessed_data[:, numeric_start_idx:]\n",
    "\n",
    "        # Ensure the scaled numeric data from the pipeline matches the manually scaled data\n",
    "        for i in range(len(self.numeric_features_h2)):\n",
    "            self.assertAlmostEqual(scaled_data[0, i], scaled_numeric_data_from_pipeline[0, i], places=6)\n",
    "            self.assertAlmostEqual(scaled_data[1, i], scaled_numeric_data_from_pipeline[1, i], places=6)\n",
    "\n",
    "# Run the test in Jupyter\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ],
   "id": "cc491ff6462c5755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Model training\n",
    "\n",
    "For this hypothesis we will be setting up and evaluating three machine learning models (Random Forest, Logistic Regression and Gradient Boosted Trees) to predict late delivery risks. Here we build separate pipelines for each model, and assessing the models using AUC (Area under the ROC Curve) to measure performance. "
   ],
   "id": "136448a1343294c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Models to be used: Random Forest, Logistic Regression, and Gradient Boosted Trees\n",
    "rf_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_2 = LogisticRegression(max_iter=500, solver='liblinear')\n",
    "gbt_2 = GradientBoostingClassifier(n_estimators=100)"
   ],
   "id": "40688d42f1015ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create pipelines for each model\n",
    "pipeline_rf_h2 = Pipeline(steps=[('preprocessor', preprocessor_h2), ('classifier', rf_2)])\n",
    "pipeline_lr_h2 = Pipeline(steps=[('preprocessor', preprocessor_h2), ('classifier', lr_2)])\n",
    "pipeline_gbt_h2 = Pipeline(steps=[('preprocessor', preprocessor_h2), ('classifier', gbt_2)])"
   ],
   "id": "ab6e9d13c02af793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df_cleaned[categorical_features_h2 + numeric_features_h1]\n",
    "y = df_cleaned['Late_delivery_risk']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "id": "b1b29b549bd4a2a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_model_2(pipeline, X_train, X_test, y_train, y_test, model_name):\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"{model_name} AUC: {auc}\")\n",
    "    return model"
   ],
   "id": "66f8011e508d5737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "rf_model_h2 = evaluate_model_2(pipeline_rf_h2, X_train, X_test, y_train, y_test, \"Random Forest\")\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model_h2 = evaluate_model_2(pipeline_lr_h2, X_train, X_test, y_train, y_test, \"Logistic Regression\")\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "gbt_model_h2 = evaluate_model_2(pipeline_gbt_h2, X_train, X_test, y_train, y_test, \"Gradient Boosting Trees\")\n"
   ],
   "id": "7427fb8664f08ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Features Importance Result Analysis\n",
    "\n",
    "Here we generate a one-hot encoded feature names for categorical variables and aligns them with the Random Forest’s feature importances. We aim to check if the number of features matches the importances, then ranks and visualizes the top 20 important features in a bar chart to highlight key drivers of late delivery risk."
   ],
   "id": "b726f2966f62827a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature importance for Random Forest model\n",
    "rf_feature_importances_h2 = rf_model_h2.named_steps['classifier'].feature_importances_"
   ],
   "id": "90eba409e197acc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine one-hot encoded features with numeric features\n",
    "one_hot_encoded_feature_names_h2 = pipeline_rf_h2.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(categorical_features_h2)\n",
    "all_feature_names_h2 = np.hstack([one_hot_encoded_feature_names_h2, numeric_features_h1])"
   ],
   "id": "79222ae2b0a6c089",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check if lengths match and display feature importances\n",
    "if len(rf_feature_importances_h2) == len(all_feature_names_h2):\n",
    "    importance_data_h2 = pd.DataFrame({\n",
    "        'Feature': all_feature_names_h2,\n",
    "        'Importance': rf_feature_importances_h2\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(importance_data_h2.head(20))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(importance_data_h2['Feature'].head(20), importance_data_h2['Importance'].head(20))\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 20 Important Features from Random Forest')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The lengths of feature names and importances do not match!\")"
   ],
   "id": "5f9253ff0fddeb6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Logistic Regression Coefficients\n",
    "\n",
    "Here we expect to understand not just the importance, but the direction of the relationship of the features and the Late Delivery Risk."
   ],
   "id": "719276267ec2db6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train Logistic Regression model and analyze coefficients\n",
    "lr_model_h2 = pipeline_lr_h2.fit(X_train, y_train)\n",
    "logistic_regression_stage_h2 = lr_model_h2.named_steps['classifier']\n",
    "coefficients_h2 = logistic_regression_stage_h2.coef_[0]\n",
    "intercept_h2 = logistic_regression_stage_h2.intercept_[0]"
   ],
   "id": "5ab6f188ac2ce45d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Combine one-hot encoded feature names with numeric features\n",
    "all_feature_names_h2 = np.hstack([one_hot_encoded_feature_names_h2, numeric_features_h1])"
   ],
   "id": "824fbea638e3bc92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create DataFrame with feature names and coefficients\n",
    "coefficient_data_h2 = pd.DataFrame({\n",
    "    'Feature': all_feature_names_h2,\n",
    "    'Coefficient': coefficients_h2\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Display top 20 coefficients\n",
    "print(\"Logistic Regression Coefficients (Hypothesis 2):\")\n",
    "print(coefficient_data_h2.head(20))"
   ],
   "id": "a2d0e3bfd742fda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the top 20 coefficients\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(coefficient_data_h2['Feature'].head(20), coefficient_data_h2['Coefficient'].head(20))\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Top 20 Logistic Regression Coefficients (Hypothesis 2)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print the intercept\n",
    "print(f\"Intercept: {intercept_h2}\")"
   ],
   "id": "88b51038b1d67315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Results and Comparison\n",
    "\n",
    "#### Hypothesis 1 Results: \n",
    "\n",
    "#### Hypothesis 2 Results:"
   ],
   "id": "9e588c9af074df7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "#### Actionable Insights:\n",
    "\n",
    "#### Next Steps:\n"
   ],
   "id": "d6693ca2c6f72dbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b2e76539ee90ad47",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
